{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Week 10: Advanced Deep Learning\n",
        "\n",
        "This week’s task focused on exploring advanced deep-learning architectures, specifically Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), using TensorFlow and Keras.\n",
        "CNNs were implemented to understand spatial feature extraction from image data, while RNNs were applied to sequential data to model temporal patterns relevant to educational performance analysis.\n",
        "\n",
        "**Dataset:**  \n",
        "- MNIST dataset (for CNN demonstration)  \n",
        "- Simulated sequential student performance data (for RNN)\n",
        "\n",
        "**Goal:**  \n",
        "Apply specialized deep-learning models (CNN and RNN) to suitable data types, analyze their learning behavior, and fulfill the project milestone of implementing an advanced AI model.\n"
      ],
      "metadata": {
        "id": "fer6mbOg3RFP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tp-9ysKizwK-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPooling2D, Flatten, Dense, Dropout,\n",
        "    SimpleRNN, LSTM, Embedding\n",
        ")\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TensorFlow Version:\", tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smXeCAiS0JR4",
        "outputId": "650f1adc-ea83-4804-df3c-9e2143b13d6f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"Training shape:\", x_train.shape)\n",
        "print(\"Testing shape:\", x_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttUerI2n0UUP",
        "outputId": "3e54ec38-7b37-45fc-d046-90c8ef8e2885"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training shape: (60000, 28, 28)\n",
            "Testing shape: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Reshape for CNN (samples, height, width, channels)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n"
      ],
      "metadata": {
        "id": "EFxVaojp0mKR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "Jkol9j3r0tSt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "XdXGIhmy07VM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_history = cnn_model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-ZSzivN1Bik",
        "outputId": "8adf3499-be32-46fb-949f-4d2594a0afd3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 50ms/step - accuracy: 0.8455 - loss: 0.4849 - val_accuracy: 0.9810 - val_loss: 0.0610\n",
            "Epoch 2/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 49ms/step - accuracy: 0.9774 - loss: 0.0740 - val_accuracy: 0.9857 - val_loss: 0.0504\n",
            "Epoch 3/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 49ms/step - accuracy: 0.9833 - loss: 0.0539 - val_accuracy: 0.9877 - val_loss: 0.0439\n",
            "Epoch 4/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9869 - loss: 0.0405 - val_accuracy: 0.9900 - val_loss: 0.0350\n",
            "Epoch 5/5\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 50ms/step - accuracy: 0.9892 - loss: 0.0347 - val_accuracy: 0.9903 - val_loss: 0.0350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_loss, cnn_acc = cnn_model.evaluate(x_test, y_test)\n",
        "print(f\"CNN Test Accuracy: {cnn_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chd09slQ11uT",
        "outputId": "51b5e9b8-fbcc-4f25-f362-7310beb49a3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0346\n",
            "CNN Test Accuracy: 0.9912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Each row represents a student's performance over time\n",
        "student_scores = [\n",
        "    [60, 62, 65, 68, 70],\n",
        "    [55, 58, 60, 63, 66],\n",
        "    [70, 72, 75, 78, 80],\n",
        "    [45, 50, 52, 55, 58]\n",
        "]\n",
        "\n",
        "labels = [1, 1, 1, 0]  # Pass(1) / Fail(0)\n"
      ],
      "metadata": {
        "id": "mMdlUM_T2Ood"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pad_sequences(student_scores, padding='post')\n",
        "y = np.array(labels)\n",
        "\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n"
      ],
      "metadata": {
        "id": "xad4kLQX2SsY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = Sequential([\n",
        "    SimpleRNN(64, activation='relu', input_shape=(X.shape[1], 1)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "0twZZE1w2XcK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "HSVASCz324Vs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_history = rnn_model.fit(\n",
        "    X, y,\n",
        "    epochs=30,\n",
        "    batch_size=2,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OST97Ia2841",
        "outputId": "9c4c0b8e-2ee3-4926-8724-efd0412ff0c1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.1667 - loss: 3.0258  \n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6667 - loss: 0.6389\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.6633\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6667 - loss: 1.3247\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6667 - loss: 1.1579\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8333 - loss: 0.4168\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.3792\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.4885\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6667 - loss: 0.6885\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6667 - loss: 0.6185\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8333 - loss: 0.4971\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6667 - loss: 0.6868\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6667 - loss: 0.7447\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8333 - loss: 0.4205\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6667 - loss: 0.7210\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8333 - loss: 0.3973\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6667 - loss: 0.6349\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8333 - loss: 0.5050\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8333 - loss: 0.4588\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6667 - loss: 0.6088\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8333 - loss: 0.4255\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.4159\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8333 - loss: 0.3948\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8333 - loss: 0.3957\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6667 - loss: 0.6346\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.4679\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8333 - loss: 0.4495\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8333 - loss: 0.4326\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8333 - loss: 0.4045\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6667 - loss: 0.6374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_history = rnn_model.fit(\n",
        "    X, y,\n",
        "    epochs=30,\n",
        "    batch_size=2,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_T8FxzA3CsK",
        "outputId": "e8aa0c81-8cf2-4b97-ee23-c8ddda7f6cda"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6667 - loss: 0.6030\n",
            "Epoch 2/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.4569\n",
            "Epoch 3/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6667 - loss: 0.5969\n",
            "Epoch 4/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8333 - loss: 0.4239\n",
            "Epoch 5/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8333 - loss: 0.4035\n",
            "Epoch 6/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.3962\n",
            "Epoch 7/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6667 - loss: 0.6312\n",
            "Epoch 8/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8333 - loss: 0.4247\n",
            "Epoch 9/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6667 - loss: 0.6032\n",
            "Epoch 10/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6667 - loss: 0.5756\n",
            "Epoch 11/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6667 - loss: 0.5759\n",
            "Epoch 12/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.4246\n",
            "Epoch 13/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.4022\n",
            "Epoch 14/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6667 - loss: 0.6741\n",
            "Epoch 15/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6667 - loss: 0.6252\n",
            "Epoch 16/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8333 - loss: 0.4281\n",
            "Epoch 17/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.4315\n",
            "Epoch 18/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6667 - loss: 0.6007\n",
            "Epoch 19/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.4398\n",
            "Epoch 20/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6667 - loss: 0.5981\n",
            "Epoch 21/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.4155\n",
            "Epoch 22/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.3929\n",
            "Epoch 23/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6667 - loss: 0.6138\n",
            "Epoch 24/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6667 - loss: 0.5948\n",
            "Epoch 25/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6667 - loss: 0.5654\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8333 - loss: 0.4509\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6667 - loss: 0.6034\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6667 - loss: 0.6075\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6667 - loss: 0.5876\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8333 - loss: 0.4088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_student = [[65, 68, 70, 73, 75]]\n",
        "test_student = pad_sequences(test_student, maxlen=X.shape[1], padding='post')\n",
        "test_student = test_student.reshape(1, X.shape[1], 1)\n",
        "\n",
        "prediction = rnn_model.predict(test_student)\n",
        "\n",
        "print(\"Pass Probability:\", prediction[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx4WuB9A3I7y",
        "outputId": "a439ad30-cd00-4bc9-ab4e-7d866f84b03b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "Pass Probability: 0.85445404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 10: Summary\n",
        "\n",
        "**Dataset:**  \n",
        "- MNIST dataset (for CNN implementation)  \n",
        "- Sequential student performance data (for RNN implementation)\n",
        "\n",
        "**Technique Used:**  \n",
        "Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) with Keras (TensorFlow backend)\n",
        "\n",
        "### Key Steps:\n",
        "1. Preprocessed image data by normalizing pixel values and reshaping inputs to meet CNN requirements.\n",
        "\n",
        "2. Built a CNN using the Sequential API with:\n",
        "\n",
        "   Convolutional layers for feature extraction  \n",
        "\n",
        "   Max-pooling layers for dimensionality reduction  \n",
        "\n",
        "   Fully connected dense layers for classification  \n",
        "\n",
        "   Dropout for regularization  \n",
        "\n",
        "3. Trained and evaluated the CNN model on test data to assess image classification performance.\n",
        "\n",
        "4. Prepared sequential student performance data by padding and reshaping it into time-series format suitable for RNN input.\n",
        "\n",
        "5. Built and trained an RNN model to learn temporal patterns in student performance trends.\n",
        "\n",
        "6. Evaluated RNN predictions on unseen sequential data.\n",
        "\n",
        "### Insights:\n",
        "- CNN effectively learned spatial patterns and features from image data.\n",
        "\n",
        "- RNN was able to capture temporal dependencies in sequential student performance data.\n",
        "\n",
        "- Advanced deep-learning models require careful data preprocessing and tuning for stable learning.\n",
        "\n",
        "- Compared to basic ANN models, CNN and RNN provide specialized architectures better suited to complex data types.\n",
        "\n",
        "**Project Milestone:**  \n",
        "Specialized deep-learning models successfully implemented — CNN for image-based learning and RNN for sequential data analysis.\n",
        "This milestone extends the project’s deep-learning component and enables future enhancements using advanced architectures and model optimization.\n"
      ],
      "metadata": {
        "id": "BFyVxFM64iAj"
      }
    }
  ]
}